name: CI

on:
  push:
    branches: [main, master]
    paths-ignore:
      - '**.md'
      - 'docs/**'
      - 'plans/**'
      - 'LICENSE'
      - '.gitignore'
  pull_request:
    branches: [main, master]
    paths-ignore:
      - '**.md'
      - 'docs/**'
      - 'plans/**'
      - 'LICENSE'
      - '.gitignore'
  # Allow manual trigger to run CI anyway
  workflow_dispatch:

concurrency:
  group: ci-${{ github.ref }}
  cancel-in-progress: true

jobs:
  frontend-lint:
    name: Frontend Lint (ESLint)
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: frontend
    steps:
      - uses: actions/checkout@v6

      - name: Setup Node.js
        uses: actions/setup-node@v6
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install dependencies
        run: npm ci

      - name: Run ESLint
        run: npm run lint

  legacy-lint:
    name: Legacy Lint (ESLint ES5)
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v6

      - name: Setup Node.js
        uses: actions/setup-node@v6
        with:
          node-version: '20'

      - name: Install ESLint
        run: npm install eslint@8 --no-save

      - name: Run ESLint on legacy JS
        run: |
          npx eslint apps/legacy/static/legacy/js/ \
            --config apps/legacy/static/legacy/.eslintrc.json \
            --ext .js \
            --format stylish || true

      - name: Generate legacy lint report
        run: |
          mkdir -p legacy-reports
          npx eslint apps/legacy/static/legacy/js/ \
            --config apps/legacy/static/legacy/.eslintrc.json \
            --ext .js \
            --format json > legacy-reports/eslint-report.json || true

          # Generate HTML report
          npx eslint apps/legacy/static/legacy/js/ \
            --config apps/legacy/static/legacy/.eslintrc.json \
            --ext .js \
            --format html > legacy-reports/eslint-report.html || true

          # Generate summary
          node << 'EOF'
          const fs = require('fs');

          let report = [];
          try {
            report = JSON.parse(fs.readFileSync('legacy-reports/eslint-report.json', 'utf8'));
          } catch (e) {
            report = [];
          }

          let errors = 0;
          let warnings = 0;
          let complexityWarnings = 0;

          report.forEach(file => {
            file.messages.forEach(msg => {
              if (msg.severity === 2) errors++;
              if (msg.severity === 1) warnings++;
              if (msg.ruleId === 'complexity') complexityWarnings++;
            });
          });

          const summary = {
            total_files: report.length,
            errors: errors,
            warnings: warnings,
            complexity_warnings: complexityWarnings,
            rating: errors > 0 ? 'D' : warnings > 10 ? 'C' : warnings > 0 ? 'B' : 'A'
          };

          fs.writeFileSync('legacy-reports/summary.json', JSON.stringify(summary, null, 2));
          console.log('Legacy lint summary:', JSON.stringify(summary, null, 2));
          EOF

      - name: Upload legacy lint artifact
        uses: actions/upload-artifact@v4
        with:
          name: legacy-lint
          path: legacy-reports/
          retention-days: 30

  backend-lint:
    name: Backend Lint (ruff)
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v6

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install ruff
        run: pip install ruff

      - name: Run ruff check
        run: ruff check apps/ cookie/ --output-format=full

      - name: Run ruff format check
        run: ruff format apps/ cookie/ --check --diff || true

      - name: Generate lint report
        run: |
          mkdir -p backend-lint
          ruff check apps/ cookie/ --output-format=json > backend-lint/ruff-report.json || true

          # Generate summary
          python3 << 'EOF'
          import json

          errors = 0
          warnings = 0
          files_with_issues = set()

          try:
              with open('backend-lint/ruff-report.json') as f:
                  issues = json.load(f)
                  for issue in issues:
                      files_with_issues.add(issue.get('filename', ''))
                      # E and W codes are typically errors/warnings
                      code = issue.get('code', '')
                      if code.startswith('E') or code.startswith('F'):
                          errors += 1
                      else:
                          warnings += 1
          except Exception as e:
              print(f"Note: Could not parse ruff output: {e}")
              issues = []

          # Rating based on error count
          if errors == 0:
              rating = 'A'
          elif errors <= 5:
              rating = 'B'
          elif errors <= 20:
              rating = 'C'
          else:
              rating = 'D'

          summary = {
              'total_issues': len(issues) if isinstance(issues, list) else 0,
              'errors': errors,
              'warnings': warnings,
              'files_with_issues': len(files_with_issues),
              'rating': rating
          }

          with open('backend-lint/summary.json', 'w') as f:
              json.dump(summary, f, indent=2)

          print(f"Backend lint summary: {json.dumps(summary, indent=2)}")
          EOF

      - name: Upload backend lint artifact
        uses: actions/upload-artifact@v4
        with:
          name: backend-lint
          path: backend-lint/
          retention-days: 30

  frontend-typecheck:
    name: Frontend Type Check (TypeScript)
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: frontend
    steps:
      - uses: actions/checkout@v6

      - name: Setup Node.js
        uses: actions/setup-node@v6
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install dependencies
        run: npm ci

      - name: Run TypeScript compiler
        run: npx tsc --noEmit

  frontend-test:
    name: Frontend Tests (Vitest)
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: frontend
    steps:
      - uses: actions/checkout@v6

      - name: Setup Node.js
        uses: actions/setup-node@v6
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install dependencies
        run: npm ci

      - name: Run Vitest with coverage
        run: npm run test:coverage

      - name: Upload frontend coverage artifact
        uses: actions/upload-artifact@v4
        with:
          name: frontend-coverage
          path: frontend/coverage/
          retention-days: 30

  backend-test:
    name: Backend Tests (pytest)
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v6

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run pytest with coverage
        run: |
          pytest tests/ \
            --cov=apps \
            --cov=cookie \
            --cov-report=xml:coverage.xml \
            --cov-report=html:htmlcov \
            --cov-report=json:coverage.json \
            --cov-report=term \
            -v
        env:
          DJANGO_SETTINGS_MODULE: cookie.settings
          DATABASE_PATH: /tmp/test_db.sqlite3

      - name: Upload backend coverage artifact
        uses: actions/upload-artifact@v4
        with:
          name: backend-coverage
          path: |
            coverage.xml
            coverage.json
            htmlcov/
          retention-days: 30

  backend-complexity:
    name: Backend Complexity (radon)
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v6

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install radon
        run: pip install radon

      - name: Generate complexity reports
        run: |
          mkdir -p complexity

          # Cyclomatic Complexity (CC) - JSON and text
          radon cc apps/ cookie/ -a -s --json > complexity/cc.json
          radon cc apps/ cookie/ -a -s > complexity/cc.txt

          # Maintainability Index (MI) - JSON and text
          radon mi apps/ cookie/ -s --json > complexity/mi.json
          radon mi apps/ cookie/ -s > complexity/mi.txt

          # Raw metrics (LOC, LLOC, SLOC, comments, etc.)
          radon raw apps/ cookie/ -s --json > complexity/raw.json

          # Halstead metrics
          radon hal apps/ cookie/ --json > complexity/hal.json

          # Generate HTML report
          echo "Generating complexity HTML report..."
          python3 << 'EOF'
          import json
          import os

          # Load complexity data
          with open('complexity/cc.json') as f:
              cc_data = json.load(f)
          with open('complexity/mi.json') as f:
              mi_data = json.load(f)

          # Calculate averages
          total_cc = 0
          cc_count = 0
          for file_path, functions in cc_data.items():
              for func in functions:
                  total_cc += func.get('complexity', 0)
                  cc_count += 1

          avg_cc = round(total_cc / cc_count, 2) if cc_count > 0 else 0

          mi_scores = [v.get('mi', 0) for v in mi_data.values() if isinstance(v, dict)]
          avg_mi = round(sum(mi_scores) / len(mi_scores), 2) if mi_scores else 0

          # Generate summary JSON
          summary = {
              'average_cyclomatic_complexity': avg_cc,
              'average_maintainability_index': avg_mi,
              'total_functions_analyzed': cc_count,
              'total_files_analyzed': len(mi_data),
              'cc_rating': 'A' if avg_cc <= 5 else 'B' if avg_cc <= 10 else 'C' if avg_cc <= 20 else 'D',
              'mi_rating': 'A' if avg_mi >= 80 else 'B' if avg_mi >= 60 else 'C' if avg_mi >= 40 else 'D'
          }

          with open('complexity/summary.json', 'w') as f:
              json.dump(summary, f, indent=2)

          print(f"Average CC: {avg_cc} ({summary['cc_rating']})")
          print(f"Average MI: {avg_mi} ({summary['mi_rating']})")

          # Generate HTML report
          html = '''<!DOCTYPE html>
          <html lang="en">
          <head>
              <meta charset="UTF-8">
              <meta name="viewport" content="width=device-width, initial-scale=1.0">
              <title>Backend Complexity Report</title>
              <style>
                  * { box-sizing: border-box; margin: 0; padding: 0; }
                  body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; max-width: 1200px; margin: 0 auto; padding: 2rem; background: #f5f5f5; }
                  h1 { margin-bottom: 0.5rem; }
                  .subtitle { color: #666; margin-bottom: 2rem; }
                  .summary { display: flex; gap: 2rem; margin-bottom: 2rem; flex-wrap: wrap; }
                  .stat { background: white; padding: 1.5rem; border-radius: 8px; text-align: center; min-width: 150px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
                  .stat-value { font-size: 2rem; font-weight: bold; }
                  .stat-label { color: #666; font-size: 0.9rem; }
                  .rating-A { color: #22c55e; }
                  .rating-B { color: #84cc16; }
                  .rating-C { color: #eab308; }
                  .rating-D { color: #ef4444; }
                  table { width: 100%; border-collapse: collapse; background: white; border-radius: 8px; overflow: hidden; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
                  th, td { padding: 0.75rem; text-align: left; border-bottom: 1px solid #e5e7eb; }
                  th { background: #f9fafb; font-weight: 600; }
                  tr:hover { background: #f9fafb; }
                  .complexity-high { color: #ef4444; font-weight: bold; }
                  .complexity-medium { color: #eab308; }
                  .complexity-low { color: #22c55e; }
                  h2 { margin: 2rem 0 1rem; }
                  .back-link { margin-bottom: 1rem; }
                  .back-link a { color: #0066cc; text-decoration: none; }
                  .back-link a:hover { text-decoration: underline; }
              </style>
          </head>
          <body>
              <div class="back-link"><a href="../">&larr; Back to Dashboard</a></div>
              <h1>Backend Complexity Report</h1>
              <p class="subtitle">Cyclomatic Complexity and Maintainability Index Analysis</p>

              <div class="summary">
                  <div class="stat">
                      <div class="stat-value rating-''' + summary['cc_rating'] + '">' + str(avg_cc) + '''</div>
                      <div class="stat-label">Avg Cyclomatic Complexity</div>
                  </div>
                  <div class="stat">
                      <div class="stat-value rating-''' + summary['mi_rating'] + '">' + str(avg_mi) + '''</div>
                      <div class="stat-label">Avg Maintainability Index</div>
                  </div>
                  <div class="stat">
                      <div class="stat-value">''' + str(cc_count) + '''</div>
                      <div class="stat-label">Functions Analyzed</div>
                  </div>
                  <div class="stat">
                      <div class="stat-value">''' + str(len(mi_data)) + '''</div>
                      <div class="stat-label">Files Analyzed</div>
                  </div>
              </div>

              <h2>Functions by Complexity</h2>
              <table>
                  <thead>
                      <tr><th>File</th><th>Function</th><th>Type</th><th>Complexity</th><th>Rating</th></tr>
                  </thead>
                  <tbody>'''

          # Sort functions by complexity (highest first)
          all_funcs = []
          for file_path, functions in cc_data.items():
              for func in functions:
                  all_funcs.append({
                      'file': file_path,
                      'name': func.get('name', 'unknown'),
                      'type': func.get('type', 'function'),
                      'complexity': func.get('complexity', 0),
                      'rank': func.get('rank', 'A')
                  })

          all_funcs.sort(key=lambda x: x['complexity'], reverse=True)

          for func in all_funcs[:100]:  # Limit to top 100
              cc_class = 'complexity-high' if func['complexity'] > 10 else 'complexity-medium' if func['complexity'] > 5 else 'complexity-low'
              html += f'''
                      <tr>
                          <td>{func['file']}</td>
                          <td>{func['name']}</td>
                          <td>{func['type']}</td>
                          <td class="{cc_class}">{func['complexity']}</td>
                          <td>{func['rank']}</td>
                      </tr>'''

          html += '''
                  </tbody>
              </table>

              <h2>File Maintainability</h2>
              <table>
                  <thead>
                      <tr><th>File</th><th>Maintainability Index</th><th>Rating</th></tr>
                  </thead>
                  <tbody>'''

          # Sort files by MI (lowest first - worst maintainability first)
          mi_list = [(f, v.get('mi', 0), v.get('rank', 'A')) for f, v in mi_data.items() if isinstance(v, dict)]
          mi_list.sort(key=lambda x: x[1])

          for file_path, mi_score, rank in mi_list:
              mi_class = 'complexity-high' if mi_score < 40 else 'complexity-medium' if mi_score < 60 else 'complexity-low'
              html += f'''
                      <tr>
                          <td>{file_path}</td>
                          <td class="{mi_class}">{round(mi_score, 1)}</td>
                          <td>{rank}</td>
                      </tr>'''

          html += '''
                  </tbody>
              </table>
          </body>
          </html>'''

          with open('complexity/radon_report.html', 'w') as f:
              f.write(html)
          print("Generated complexity/radon_report.html")
          EOF

      - name: Upload complexity artifact
        uses: actions/upload-artifact@v4
        with:
          name: backend-complexity
          path: complexity/
          retention-days: 30

  frontend-complexity:
    name: Frontend Complexity (ESLint)
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: frontend
    steps:
      - uses: actions/checkout@v6

      - name: Setup Node.js
        uses: actions/setup-node@v6
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install dependencies
        run: npm ci

      - name: Generate complexity report
        run: |
          mkdir -p complexity

          # Run ESLint with complexity rules and JSON output
          npx eslint src/ \
            --rule '{"complexity": ["warn", 10]}' \
            --rule '{"max-depth": ["warn", 4]}' \
            --rule '{"max-nested-callbacks": ["warn", 3]}' \
            --rule '{"max-lines-per-function": ["warn", 50]}' \
            -f json > complexity/eslint-report.json || true

          # Count lines of code
          echo '{}' > complexity/loc.json
          find src -name '*.ts' -o -name '*.tsx' | head -100 | while read file; do
            wc -l "$file"
          done > complexity/loc.txt || true

          # Generate summary
          node << 'EOF'
          const fs = require('fs');

          let report = [];
          try {
            report = JSON.parse(fs.readFileSync('complexity/eslint-report.json', 'utf8'));
          } catch (e) {
            report = [];
          }

          let complexityWarnings = 0;
          let totalFiles = report.length;

          report.forEach(file => {
            file.messages.forEach(msg => {
              if (msg.ruleId === 'complexity') complexityWarnings++;
            });
          });

          const summary = {
            total_files: totalFiles,
            complexity_warnings: complexityWarnings,
            rating: complexityWarnings === 0 ? 'A' : complexityWarnings <= 5 ? 'B' : complexityWarnings <= 10 ? 'C' : 'D'
          };

          fs.writeFileSync('complexity/summary.json', JSON.stringify(summary, null, 2));
          console.log('Frontend complexity:', JSON.stringify(summary));
          EOF

      - name: Upload complexity artifact
        uses: actions/upload-artifact@v4
        with:
          name: frontend-complexity
          path: frontend/complexity/
          retention-days: 30

  frontend-duplication:
    name: Frontend Duplication (jscpd)
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: frontend
    steps:
      - uses: actions/checkout@v6

      - name: Setup Node.js
        uses: actions/setup-node@v6
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install dependencies
        run: npm ci

      - name: Run copy-paste detection
        run: |
          mkdir -p duplication
          npx jscpd src/ \
            --min-tokens 50 \
            --min-lines 5 \
            --reporters json,console,html \
            --output duplication/ \
            --format 'typescript,tsx' \
            --ignore '**/test/**,**/*.test.*' || true

          # Generate summary
          node << 'EOF'
          const fs = require('fs');

          let report = { statistics: { total: { percentage: 0, duplicatedLines: 0, lines: 0 } } };
          try {
            report = JSON.parse(fs.readFileSync('duplication/jscpd-report.json', 'utf8'));
          } catch (e) {
            console.log('No duplication report found, creating empty summary');
          }

          const stats = report.statistics?.total || { percentage: 0, duplicatedLines: 0, lines: 0 };
          const summary = {
            duplication_percentage: Math.round(stats.percentage * 100) / 100,
            duplicated_lines: stats.duplicatedLines || 0,
            total_lines: stats.lines || 0,
            clones_count: report.duplicates?.length || 0,
            rating: stats.percentage <= 3 ? 'A' : stats.percentage <= 5 ? 'B' : stats.percentage <= 10 ? 'C' : 'D'
          };

          fs.writeFileSync('duplication/summary.json', JSON.stringify(summary, null, 2));
          console.log('Duplication summary:', JSON.stringify(summary, null, 2));
          EOF

      - name: Upload duplication artifact
        uses: actions/upload-artifact@v4
        with:
          name: frontend-duplication
          path: frontend/duplication/
          retention-days: 30

  legacy-duplication:
    name: Legacy Duplication (jscpd)
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v6

      - name: Setup Node.js
        uses: actions/setup-node@v6
        with:
          node-version: '20'

      - name: Run copy-paste detection on legacy JS
        run: |
          mkdir -p legacy-duplication
          npx jscpd apps/legacy/static/legacy/js/ \
            --min-tokens 30 \
            --min-lines 4 \
            --reporters json,console,html \
            --output legacy-duplication/ \
            --format 'javascript' || true

          # Generate summary
          node << 'EOF'
          const fs = require('fs');

          let report = { statistics: { total: { percentage: 0, duplicatedLines: 0, lines: 0 } } };
          try {
            report = JSON.parse(fs.readFileSync('legacy-duplication/jscpd-report.json', 'utf8'));
          } catch (e) {
            console.log('No duplication report found, creating empty summary');
          }

          const stats = report.statistics?.total || { percentage: 0, duplicatedLines: 0, lines: 0 };
          const summary = {
            duplication_percentage: Math.round(stats.percentage * 100) / 100,
            duplicated_lines: stats.duplicatedLines || 0,
            total_lines: stats.lines || 0,
            clones_count: report.duplicates?.length || 0,
            rating: stats.percentage <= 5 ? 'A' : stats.percentage <= 10 ? 'B' : stats.percentage <= 15 ? 'C' : 'D'
          };

          fs.writeFileSync('legacy-duplication/summary.json', JSON.stringify(summary, null, 2));
          console.log('Legacy duplication summary:', JSON.stringify(summary, null, 2));
          EOF

      - name: Upload legacy duplication artifact
        uses: actions/upload-artifact@v4
        with:
          name: legacy-duplication
          path: legacy-duplication/
          retention-days: 30

  backend-duplication:
    name: Backend Duplication (jscpd)
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v6

      - name: Setup Node.js
        uses: actions/setup-node@v6
        with:
          node-version: '20'

      - name: Run copy-paste detection on Python
        run: |
          mkdir -p backend-duplication
          npx jscpd apps/ cookie/ \
            --min-tokens 50 \
            --min-lines 5 \
            --reporters json,console,html \
            --output backend-duplication/ \
            --format 'python' \
            --ignore '**/migrations/**,**/tests.py,**/__pycache__/**' || true

          # Generate summary
          node << 'EOF'
          const fs = require('fs');

          let report = { statistics: { total: { percentage: 0, duplicatedLines: 0, lines: 0 } } };
          try {
            report = JSON.parse(fs.readFileSync('backend-duplication/jscpd-report.json', 'utf8'));
          } catch (e) {
            console.log('No duplication report found, creating empty summary');
          }

          const stats = report.statistics?.total || { percentage: 0, duplicatedLines: 0, lines: 0 };
          const summary = {
            duplication_percentage: Math.round(stats.percentage * 100) / 100,
            duplicated_lines: stats.duplicatedLines || 0,
            total_lines: stats.lines || 0,
            clones_count: report.duplicates?.length || 0,
            rating: stats.percentage <= 3 ? 'A' : stats.percentage <= 5 ? 'B' : stats.percentage <= 10 ? 'C' : 'D'
          };

          fs.writeFileSync('backend-duplication/summary.json', JSON.stringify(summary, null, 2));
          console.log('Backend duplication summary:', JSON.stringify(summary, null, 2));
          EOF

      - name: Upload backend duplication artifact
        uses: actions/upload-artifact@v4
        with:
          name: backend-duplication
          path: backend-duplication/
          retention-days: 30

  frontend-security:
    name: Frontend Security (npm audit)
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: frontend
    steps:
      - uses: actions/checkout@v6

      - name: Setup Node.js
        uses: actions/setup-node@v6
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install dependencies
        run: npm ci

      - name: Run npm audit
        run: |
          mkdir -p security
          npm audit --json > security/npm-audit.json || true
          npm audit > security/npm-audit.txt || true

          # Generate summary
          node << 'EOF'
          const fs = require('fs');

          let audit = { metadata: { vulnerabilities: { total: 0, critical: 0, high: 0, moderate: 0, low: 0 } } };
          try {
            audit = JSON.parse(fs.readFileSync('security/npm-audit.json', 'utf8'));
          } catch (e) {
            console.log('Could not parse audit JSON');
          }

          const vulns = audit.metadata?.vulnerabilities || { total: 0, critical: 0, high: 0, moderate: 0, low: 0 };
          const summary = {
            total_vulnerabilities: vulns.total || 0,
            critical: vulns.critical || 0,
            high: vulns.high || 0,
            moderate: vulns.moderate || 0,
            low: vulns.low || 0,
            rating: vulns.critical > 0 ? 'D' : vulns.high > 0 ? 'C' : vulns.moderate > 0 ? 'B' : 'A'
          };

          fs.writeFileSync('security/summary.json', JSON.stringify(summary, null, 2));
          console.log('Security summary:', JSON.stringify(summary, null, 2));
          EOF

      - name: Upload security artifact
        uses: actions/upload-artifact@v4
        with:
          name: frontend-security
          path: frontend/security/
          retention-days: 30

  backend-security:
    name: Backend Security (pip-audit + Bandit SAST)
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v6

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run pip-audit (dependency vulnerabilities)
        run: |
          mkdir -p security
          pip-audit --format json --output security/pip-audit.json || true
          pip-audit > security/pip-audit.txt || true

      - name: Run Bandit SAST (code security analysis)
        run: |
          # Run Bandit on application code, excluding tests and migrations
          bandit -r apps/ \
            --exclude "*/tests.py,*/test_*.py,*/migrations/*" \
            -f json -o security/bandit.json || true
          bandit -r apps/ \
            --exclude "*/tests.py,*/test_*.py,*/migrations/*" \
            -f txt -o security/bandit.txt || true

      - name: Generate combined security summary
        run: |
          python3 << 'EOF'
          import json

          # Parse pip-audit results
          pip_vulns = 0
          try:
              with open('security/pip-audit.json') as f:
                  data = json.load(f)
                  if isinstance(data, dict):
                      for dep in data.get('dependencies', []):
                          pip_vulns += len(dep.get('vulns', []))
                  elif isinstance(data, list):
                      pip_vulns = len(data)
          except Exception as e:
              print(f"Note: Could not parse pip-audit output: {e}")

          # Parse Bandit results
          bandit_issues = {'HIGH': 0, 'MEDIUM': 0, 'LOW': 0}
          try:
              with open('security/bandit.json') as f:
                  data = json.load(f)
                  for result in data.get('results', []):
                      severity = result.get('issue_severity', 'LOW')
                      bandit_issues[severity] = bandit_issues.get(severity, 0) + 1
          except Exception as e:
              print(f"Note: Could not parse Bandit output: {e}")

          # Calculate combined rating
          # pip-audit: any vulnerability is concerning
          # Bandit: HIGH issues are critical, MEDIUM are notable
          high_severity = pip_vulns + bandit_issues['HIGH']
          medium_severity = bandit_issues['MEDIUM']

          if high_severity == 0 and medium_severity == 0:
              rating = 'A'
          elif high_severity == 0 and medium_severity <= 3:
              rating = 'B'
          elif high_severity <= 2:
              rating = 'C'
          else:
              rating = 'D'

          summary = {
              'pip_audit': {'vulnerabilities': pip_vulns},
              'bandit': {
                  'high': bandit_issues['HIGH'],
                  'medium': bandit_issues['MEDIUM'],
                  'low': bandit_issues['LOW'],
                  'total': sum(bandit_issues.values())
              },
              'total_high_severity': high_severity,
              'rating': rating
          }

          with open('security/summary.json', 'w') as f:
              json.dump(summary, f, indent=2)

          print(f"Security summary: {json.dumps(summary, indent=2)}")
          EOF

      - name: Upload security artifact
        uses: actions/upload-artifact@v4
        with:
          name: backend-security
          path: security/
          retention-days: 30

  secrets-detection:
    name: Secrets Detection
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v6
        with:
          fetch-depth: 0  # Full history for accurate scanning

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install detect-secrets
        run: pip install detect-secrets

      - name: Scan for secrets
        run: |
          mkdir -p security

          # Scan for new secrets against baseline
          detect-secrets scan \
            --baseline .secrets.baseline \
            --exclude-files '\.lock$' \
            --exclude-files 'package-lock\.json$' \
            --exclude-files 'node_modules/' \
            --exclude-files 'dist/' \
            --exclude-files '\.secrets\.baseline$' \
            > security/secrets-scan.json 2>&1 || true

          # Check if any new secrets were found
          python3 << 'EOF'
          import json
          import sys

          try:
              with open('security/secrets-scan.json') as f:
                  results = json.load(f)

              secrets_found = results.get('results', {})
              total_secrets = sum(len(v) for v in secrets_found.values())

              if total_secrets > 0:
                  print(f"‚ö†Ô∏è  Found {total_secrets} potential secret(s) in {len(secrets_found)} file(s):")
                  for filename, secrets in secrets_found.items():
                      print(f"\n  üìÅ {filename}:")
                      for secret in secrets:
                          print(f"     Line {secret.get('line_number', '?')}: {secret.get('type', 'unknown type')}")
                  print("\n‚ùå Please review and remove secrets, or update .secrets.baseline if false positives.")
                  sys.exit(1)
              else:
                  print("‚úÖ No secrets detected")
          except json.JSONDecodeError:
              print("‚ö†Ô∏è  Could not parse scan results")
          except FileNotFoundError:
              print("‚ö†Ô∏è  Scan results file not found")
          EOF

      - name: Upload secrets scan artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: secrets-detection
          path: security/
          retention-days: 30

  frontend-bundle:
    name: Frontend Bundle Analysis
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: frontend
    steps:
      - uses: actions/checkout@v6

      - name: Setup Node.js
        uses: actions/setup-node@v6
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install dependencies
        run: npm ci

      - name: Build and analyze bundle
        run: |
          mkdir -p bundle
          npm run build

          # Analyze bundle sizes
          node << 'EOF'
          const fs = require('fs');
          const path = require('path');

          const distDir = 'dist/assets';
          let totalSize = 0;
          let jsSize = 0;
          let cssSize = 0;
          const files = [];

          if (fs.existsSync(distDir)) {
            fs.readdirSync(distDir).forEach(file => {
              // Skip source maps - they aren't served to users
              if (file.endsWith('.map')) return;

              const filePath = path.join(distDir, file);
              const stats = fs.statSync(filePath);
              const sizeKB = Math.round(stats.size / 1024 * 100) / 100;
              totalSize += stats.size;

              if (file.endsWith('.js')) jsSize += stats.size;
              if (file.endsWith('.css')) cssSize += stats.size;

              files.push({ name: file, size_kb: sizeKB });
            });
          }

          const summary = {
            total_size_kb: Math.round(totalSize / 1024 * 100) / 100,
            js_size_kb: Math.round(jsSize / 1024 * 100) / 100,
            css_size_kb: Math.round(cssSize / 1024 * 100) / 100,
            files: files.sort((a, b) => b.size_kb - a.size_kb),
            rating: totalSize < 500000 ? 'A' : totalSize < 1000000 ? 'B' : totalSize < 2000000 ? 'C' : 'D'
          };

          fs.writeFileSync('bundle/summary.json', JSON.stringify(summary, null, 2));
          console.log('Bundle summary:', JSON.stringify(summary, null, 2));
          EOF

      - name: Upload bundle artifact
        uses: actions/upload-artifact@v4
        with:
          name: frontend-bundle
          path: frontend/bundle/
          retention-days: 30

  ci-success:
    name: CI Success
    runs-on: ubuntu-latest
    needs: [frontend-lint, frontend-typecheck, frontend-test, backend-test, backend-lint, backend-complexity, frontend-complexity, frontend-duplication, backend-duplication, legacy-lint, legacy-duplication]
    if: always()
    steps:
      - name: Check all jobs passed
        run: |
          # Core jobs must pass
          if [[ "${{ needs.frontend-lint.result }}" != "success" ]] || \
             [[ "${{ needs.frontend-typecheck.result }}" != "success" ]] || \
             [[ "${{ needs.frontend-test.result }}" != "success" ]] || \
             [[ "${{ needs.backend-test.result }}" != "success" ]] || \
             [[ "${{ needs.backend-lint.result }}" != "success" ]]; then
            echo "One or more core CI jobs failed"
            exit 1
          fi
          # Frontend quality jobs must pass
          if [[ "${{ needs.frontend-complexity.result }}" != "success" ]] || \
             [[ "${{ needs.frontend-duplication.result }}" != "success" ]]; then
            echo "Frontend quality checks failed"
            exit 1
          fi
          # Legacy JS quality jobs must pass
          if [[ "${{ needs.legacy-lint.result }}" != "success" ]] || \
             [[ "${{ needs.legacy-duplication.result }}" != "success" ]]; then
            echo "Legacy JS quality checks failed"
            exit 1
          fi
          # Backend analysis jobs are informational (warn but don't fail)
          if [[ "${{ needs.backend-complexity.result }}" != "success" ]]; then
            echo "Warning: Backend complexity analysis had issues, but continuing..."
          fi
          if [[ "${{ needs.backend-duplication.result }}" != "success" ]]; then
            echo "Warning: Backend duplication analysis had issues, but continuing..."
          fi
          echo "All CI jobs passed successfully"
